搜索相关新是搜索的核心模块之一，决定了用户查询Query与返回Doc的内容匹配程度，是判断返回结果是否能满足用户的需求的决定因素之一。\
**相关性标准**  
不同的搜索产品虽然在标准上会有一些差异，但目前比较通用的标准主要是采用以下5档分级来衡量查询和文档的相关程度：  
* 0：完全不相关(Not Relevant)
  * 定义：文档与查询没有任何关联
  * 说明：完全无法满足用户的主需和次需，对用户没有任何帮助
* 1：略微相关(Marginally Relevant)
  * 定义：文档与查询在某一些方面有关，但对用户问题的解答效果很差
  * 说明：对用户需求几乎没有任何帮助，没有覆盖用户的主需和次需，仅包含少量无关紧要的信息，文档主题和查询存在部分语义或者背景的弱相关性，但不直接匹配
* 2：部分相关(partially Relevant)
  * 定义：文档与查询有一定的相关性，可以部分回答用户的问题活满足查询需求
  * 说明：文档可能涉及与查询相关的主题，但无法直接满足查询的核心需求，信息不全面、不精确、或者次需偏离
* 3：高度相关(Highly Relevant)
  * 定义：文档与查询紧密相关，可以完全满足用户的需求
  * 说明：内容与用户预期匹配，主题一致，但可能有次要需求不够好
* 4：完全相关(Perfectly Relevant)
  * 定义：文档与查询完全匹配，解决了查询的所有需求，符合用户预期
  * 说明：完全满足

**相关性技术**  
目前主流的相关性技术是采用预训练的语义模型(Bert),另外，传统的文本匹配和GBDT模型依然在某一些场景下可以使用  
* 文本匹配
传统的相关性技术主要依赖统计信息，常见的有tf-idf和BM25，其基本的思想是Query中的词在Doc中出现次数越多，则越相关，其中可以进一步优化的是加入同义词匹配以及词权重信息，而BM25进一步考虑了Doc的长度进行归一化，这里不展开细说  
* GBDT
gbdt是一种基于梯度提升框架的集成学习方法，通过蒋多个弱分类器（通常是决策树）进行集成，来优化模型的预测结果，比较常用的gbdt框架有xgboost和lightgbm。
输入特征可以是query特征、doc特征以及query&doc交互特征，除了文本特征、还可以有类别、主题、实体等特征，以及统计特征
* Bert双塔模型
Bert的双塔模型分为Query塔和Doc塔， 其中Query塔的输入通常是Query文本加上Query的Ner、类目等文本特征， Doc塔的输入一般为文档标题、正文内容、关键词、主题、摘要等文本特征，如果文档内容过长，则需要做截断处理或者提取文档摘要作为输入， 因为双塔计算比较简单，以及粗排阶段要计算的doc比较多，一般作为粗排截断的相关性计算中
* Bert单塔模型
单塔模型是基于交互的，能够捕捉Query和Doc之间的细粒度交互信息，计算量比较大，普遍应用在精排阶段的相关性计算中

**Bert模型训练**  
基于Bert的相关性模型通常需要多阶段的训练，来逐步优化相关性效果  
* 通用预训练
* 领域预训练
* 领域微调
* 任务微调
这里还有很多数据预处理的工作，比如说对于长内容来说，可能需要抽取摘要，核心内容，ner识别等

**模型蒸馏**  
* 蒸馏算法
  * 硬标签损失：基于真实标签计算的损失，通常使用交叉熵损失
  * 软标签损失：通过教师模型的输出（概率分布）作为标签来计算，软标签的损失通常使用KL散度来度量教师模型和学生模型的输出分布的差异
  * 总损失函数：是硬标签损失和软标签损失的加权和
  * 温度调节：就是对教师模型的原始logit输出利用问题T(一般大于1)进行平滑后再进行softmax计算。

**样本构建**  
* 正样本：高点击样本
* 负样本：
  * skip-above采样：选取在点击文档之前且ctr小于阈值的充分曝光的文档作为负例
  * batch内随机负采样
  * 全局随机负采样
**参考文献**\
1、https://www.cnblogs.com/the-big-bang/articles/18619877  
